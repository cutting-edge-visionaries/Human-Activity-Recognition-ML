{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from Data_manipulation_utils import *\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "from sklearn.svm import SVC\n",
    "# For scoring\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of cleaned raw data\n",
      "Shape of X :  (814400, 6)\n",
      "Shape of Y :  (814400,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of cleaned raw data\")\n",
    "print(\"Shape of X : \", X.shape)\n",
    "print(\"Shape of Y : \", Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation Dataset to Train from raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, x2, x3, x4, x5, x6, x7, x8, x9, x10, x11, x12 = split_data_labelwise(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectrogram readings of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 15\n",
    "l = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_x1, y1 = feature_extraction_from_rawdata(x1, label = 1, S = s, L = l)\n",
    "s_x2, y2 = feature_extraction_from_rawdata(x2, label = 2, S = s, L = l)\n",
    "s_x3, y3 = feature_extraction_from_rawdata(x3, label = 3, S = s, L = l)\n",
    "s_x4, y4 = feature_extraction_from_rawdata(x4, label = 4, S = s, L = l)\n",
    "s_x5, y5 = feature_extraction_from_rawdata(x5, label = 5, S = s, L = l)\n",
    "s_x6, y6 = feature_extraction_from_rawdata(x6, label = 6, S = s, L = l)\n",
    "s_x7, y7 = feature_extraction_from_rawdata(x7, label = 7, S = s, L = l)\n",
    "s_x8, y8 = feature_extraction_from_rawdata(x8, label = 8, S = s, L = l)\n",
    "s_x9, y9 = feature_extraction_from_rawdata(x9, label = 9, S = s, L = l)\n",
    "s_x10, y10 = feature_extraction_from_rawdata(x10, label = 10, S = s, L = l)\n",
    "s_x11, y11 = feature_extraction_from_rawdata(x11, label = 11, S = s, L = l)\n",
    "s_x12, y12 = feature_extraction_from_rawdata(x12, label = 12, S = s, L = l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Domain Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx1 = time_domain_features_from_rawdata(x1)\n",
    "tx2 = time_domain_features_from_rawdata(x2)\n",
    "tx3 = time_domain_features_from_rawdata(x3)\n",
    "tx4 = time_domain_features_from_rawdata(x4)\n",
    "tx5 = time_domain_features_from_rawdata(x5)\n",
    "tx6 = time_domain_features_from_rawdata(x6)\n",
    "tx7 = time_domain_features_from_rawdata(x7)\n",
    "tx8 = time_domain_features_from_rawdata(x8)\n",
    "tx9 = time_domain_features_from_rawdata(x9)\n",
    "tx10 = time_domain_features_from_rawdata(x10)\n",
    "tx11 = time_domain_features_from_rawdata(x11)\n",
    "tx12 = time_domain_features_from_rawdata(x12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xf = np.vstack((s_x1, s_x2, s_x3, s_x4, s_x5, s_x6, s_x7, s_x8, s_x9, s_x10, s_x11, s_x12))\n",
    "Xt = np.vstack((tx1, tx2, tx3, tx4, tx5, tx6, tx7, tx8, tx9, tx10, tx11, tx12))\n",
    "Xtf = np.hstack((Xf, Xt))\n",
    "\n",
    "Ytf = np.hstack((y1, y2, y3, y4, y5, y6, y7, y8, y9, y10, y11, y12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Xtf : (3166, 120)\n",
      "Shape of Ytf : (3166,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of Xtf :\", Xtf.shape)\n",
    "print(\"Shape of Ytf :\", Ytf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequency Domain Dataset with Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 100\n",
    "l = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sx1, y1 = feature_extraction_from_rawdata(x1, label = 1, S = s, L = l)\n",
    "Sx2, y2 = feature_extraction_from_rawdata(x2, label = 2, S = s, L = l)\n",
    "Sx3, y3 = feature_extraction_from_rawdata(x3, label = 3, S = s, L = l)\n",
    "Sx4, y4 = feature_extraction_from_rawdata(x4, label = 4, S = s, L = l)\n",
    "Sx5, y5 = feature_extraction_from_rawdata(x5, label = 5, S = s, L = l)\n",
    "Sx6, y6 = feature_extraction_from_rawdata(x6, label = 6, S = s, L = l)\n",
    "Sx7, y7 = feature_extraction_from_rawdata(x7, label = 7, S = s, L = l)\n",
    "Sx8, y8 = feature_extraction_from_rawdata(x8, label = 8, S = s, L = l)\n",
    "Sx9, y9 = feature_extraction_from_rawdata(x9, label = 9, S = s, L = l)\n",
    "Sx10, y10 = feature_extraction_from_rawdata(x10, label = 10, S = s, L = l)\n",
    "Sx11, y11 = feature_extraction_from_rawdata(x11, label = 11, S = s, L = l)\n",
    "Sx12, y12 = feature_extraction_from_rawdata(x12, label = 12, S = s, L = l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation\n",
    "\n",
    "### Local Averaging with window_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sx1, y1 = local_averaging(Sx1, 4, 1, shuffle = True)\n",
    "Sx2, y2 = local_averaging(Sx2, 4, 2, shuffle = True)\n",
    "Sx3, y3 = local_averaging(Sx3, 4, 3, shuffle = True)\n",
    "Sx4, y4 = local_averaging(Sx4, 4, 4, shuffle = True)\n",
    "Sx5, y5 = local_averaging(Sx5, 4, 5, shuffle = True)\n",
    "Sx6, y6 = local_averaging(Sx6, 4, 6, shuffle = True)\n",
    "Sx7, y7 = local_averaging(Sx7, 4, 7, shuffle = True)\n",
    "Sx8, y8 = local_averaging(Sx8, 4, 8, shuffle = True)\n",
    "Sx9, y9 = local_averaging(Sx9, 4, 9, shuffle = True)\n",
    "Sx10, y10 = local_averaging(Sx10, 4, 10, shuffle = True)\n",
    "Sx11, y11 = local_averaging(Sx11, 4, 11, shuffle = True)\n",
    "Sx12, y12 = local_averaging(Sx12, 4, 12, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Averaging with window_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sx1, y1 = local_averaging(Sx1, 2, 1, shuffle = False)\n",
    "Sx2, y2 = local_averaging(Sx2, 2, 2, shuffle = False)\n",
    "Sx3, y3 = local_averaging(Sx3, 2, 3, shuffle = False)\n",
    "Sx4, y4 = local_averaging(Sx4, 2, 4, shuffle = False)\n",
    "Sx5, y5 = local_averaging(Sx5, 2, 5, shuffle = False)\n",
    "Sx6, y6 = local_averaging(Sx6, 2, 6, shuffle = False)\n",
    "Sx7, y7 = local_averaging(Sx7, 2, 7, shuffle = False)\n",
    "Sx8, y8 = local_averaging(Sx8, 2, 8, shuffle = False)\n",
    "Sx9, y9 = local_averaging(Sx9, 2, 9, shuffle = False)\n",
    "Sx10, y10 = local_averaging(Sx10, 2, 10, shuffle = False)\n",
    "Sx11, y11 = local_averaging(Sx11, 2, 11, shuffle = False)\n",
    "Sx12, y12 = local_averaging(Sx12, 2, 12, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Dataset to Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fa = np.vstack((Sx1, Sx2, Sx3, Sx4, Sx5, Sx6, Sx7, Sx8, Sx9, Sx10, Sx11, Sx12))\n",
    "Y_fa = np.vstack((y1, y2, y3, y4, y5, y6, y7, y8, y9, y10, y11, y12)).reshape(X_fa.shape[0],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train :  (12664, 400)\n",
      "Shape of Y_train :  (12664,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X_train : \", X_fa.shape)\n",
    "print(\"Shape of Y_train : \", Y_fa.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model with only frequency domain features with Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      "[[1738  150   12    0    0    0    0    0    0    0    0    0]\n",
      " [ 252 1499   65    0    0    0    0    0    0    0    0    0]\n",
      " [  44   94 1537    0    0    1    0    0    0    0    0    0]\n",
      " [   0    0    0  653   54 1265    0    0    0    0    0    0]\n",
      " [   0    0    0   93 1210  849    0    0    0    0    0    0]\n",
      " [   0    0    0  139   73 1920    0    0    0    0    0    0]\n",
      " [   2    4    0    0    0    0  150    0    0    0    0    0]\n",
      " [   1    2    0    0    0    0    0  117    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0  186    0    2    0]\n",
      " [   0    0    0    0    0    0    0    0    2  165    0    1]\n",
      " [   0    0    0    0    0    0    0    0    5    1  210    4]\n",
      " [   0    0    0    0    0    0    0    0    2    1    1  160]]\n",
      "\n",
      "Training Model with only frequency domain features with Data Augmentation :\n",
      "Accuracy of model : 75.37 %\n"
     ]
    }
   ],
   "source": [
    "# Fitting SVM to the Training set\n",
    "\n",
    "classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "classifier.fit(X_fa, Y_fa)\n",
    "\n",
    "y_pred = classifier.predict(X_fa)\n",
    "\n",
    "cm = confusion_matrix(Y_fa, y_pred)\n",
    "print('Confusion Matrix : ')\n",
    "print(cm)\n",
    "print()\n",
    "\n",
    "acc = accuracy_score(Y_fa,y_pred)\n",
    "print(\"Training Model with only frequency domain features with Data Augmentation :\")\n",
    "print(\"Accuracy of model :\", round(acc*100, 2), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Dataset with 60 frequency + 60 time features :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix :\n",
      "[[472   2   1   0   0   0   0   0   0   0   0   0]\n",
      " [  4 450   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0 419   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0 467  26   0   0   0   0   0   0   0]\n",
      " [  0   0   0  26 512   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 533   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  30   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  47   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  42   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  55   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  41]]\n",
      "\n",
      "Training Dataset with 60 frequency + 60 time features :\n",
      "Accuracy of model : 98.14 %\n"
     ]
    }
   ],
   "source": [
    "classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "classifier.fit(Xtf, Ytf)\n",
    "\n",
    "y_pred = classifier.predict(Xtf)\n",
    "\n",
    "cm = confusion_matrix(Ytf, y_pred)\n",
    "print(\"Confusion Matrix :\")\n",
    "print(cm)\n",
    "print()\n",
    "\n",
    "acc = accuracy_score(Ytf,y_pred)\n",
    "print(\"Training Dataset with 60 frequency + 60 time features :\")\n",
    "print(\"Accuracy of model :\",round(acc*100, 2), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
